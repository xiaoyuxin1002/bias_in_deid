{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc0bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "import jsonlines\n",
    "from collections import defaultdict\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1f535",
   "metadata": {},
   "source": [
    "### General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697994d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/General/Input/notes-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6d459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the service\n",
    "\n",
    "info = json.load(open(os.environ['MICROSOFT_CREDENTIALS']))\n",
    "credential = AzureKeyCredential(info['key'])\n",
    "client = TextAnalyticsClient(endpoint=info['endpoint'], credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d776d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 1000\n",
      "Finish Processing Note 2000\n",
      "Finish Processing Note 3000\n",
      "Finish Processing Note 4000\n",
      "Finish Processing Note 5000\n",
      "Finish Processing Note 6000\n",
      "Finish Processing Note 7000\n",
      "Finish Processing Note 8000\n",
      "Finish Processing Note 9000\n",
      "Finish Processing Note 10000\n",
      "Finish Processing Note 11000\n",
      "Finish Processing Note 12000\n",
      "Finish Processing Note 13000\n",
      "Finish Processing Note 14000\n",
      "Finish Processing Note 15000\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "width = 5120\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    texts = textwrap.wrap(note, width, \n",
    "                          break_long_words=False, break_on_hyphens=False, \n",
    "                          replace_whitespace=False, drop_whitespace=False)\n",
    "    responses = client.recognize_pii_entities(texts)\n",
    "    \n",
    "    size = 0\n",
    "    for text, response in zip(texts, responses):\n",
    "        for entity in response.entities:\n",
    "            if entity.category == 'Person':\n",
    "                outputs[ID][(size+entity.offset, size+entity.offset+entity.length)] = (entity.text, entity.confidence_score)\n",
    "        size += len(text)\n",
    "    \n",
    "    if count % 100 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902c188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/General/Output/notes-Microsoft.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':list(name)} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6116ec",
   "metadata": {},
   "source": [
    "### Polysemy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cac9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9883044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a language resource to obtain the key and endpoint, install the azure client library\n",
    "# load the service\n",
    "\n",
    "info = json.load(open(os.environ['MICROSOFT_CREDENTIALS']))\n",
    "credential = AzureKeyCredential(info['key'])\n",
    "client = TextAnalyticsClient(endpoint=info['endpoint'], credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1299f7c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 100\n",
      "Finish Processing Note 200\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "width = 5120\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    texts = textwrap.wrap(note, width, \n",
    "                          break_long_words=False, break_on_hyphens=False, \n",
    "                          replace_whitespace=False, drop_whitespace=False)\n",
    "    responses = client.recognize_pii_entities(texts)\n",
    "    \n",
    "    size = 0\n",
    "    for text, response in zip(texts, responses):\n",
    "        for entity in response.entities:\n",
    "            if entity.category == 'Person':\n",
    "                outputs[ID][(size+entity.offset, size+entity.offset+entity.length)] = (entity.text, entity.confidence_score)\n",
    "        size += len(text)\n",
    "    \n",
    "    if count % 100 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94392635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/Polysemy/Output/polysemies-Microsoft.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':list(name)} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
