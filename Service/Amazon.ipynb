{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0fb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import textwrap\n",
    "import jsonlines\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44a084",
   "metadata": {},
   "source": [
    "### General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfd8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/General/Input/notes-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48d65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the service\n",
    "\n",
    "client = boto3.client(service_name='comprehendmedical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afc416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 1000\n",
      "Finish Processing Note 2000\n",
      "Finish Processing Note 3000\n",
      "Finish Processing Note 4000\n",
      "Finish Processing Note 5000\n",
      "Finish Processing Note 6000\n",
      "Finish Processing Note 7000\n",
      "Finish Processing Note 8000\n",
      "Finish Processing Note 9000\n",
      "Finish Processing Note 10000\n",
      "Finish Processing Note 11000\n",
      "Finish Processing Note 12000\n",
      "Finish Processing Note 13000\n",
      "Finish Processing Note 14000\n",
      "Finish Processing Note 15000\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "width = 20000\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    texts = textwrap.wrap(note, width, \n",
    "                          break_long_words=False, break_on_hyphens=False, \n",
    "                          replace_whitespace=False, drop_whitespace=False)\n",
    "    \n",
    "    size = 0\n",
    "    for text in texts:\n",
    "        result = client.detect_phi(Text=text)\n",
    "        for entity in result['Entities']:\n",
    "            if entity['Type'] == 'NAME':\n",
    "                outputs[ID][(size+entity['BeginOffset'], size+entity['EndOffset'])] = (entity['Text'], entity['Score'])\n",
    "        size += len(text)\n",
    "    \n",
    "    if count % 1000 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1021c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/General/Output/notes-Amazon.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':list(name)} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c8286",
   "metadata": {},
   "source": [
    "### Polysemy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49bd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49ec15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the AWS CLI, set up an IAM account with credentials, configure the AWS CLI, check the billing information\n",
    "# load the service\n",
    "\n",
    "client = boto3.client(service_name='comprehendmedical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3dfb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 100\n",
      "Finish Processing Note 200\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "width = 20000\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    texts = textwrap.wrap(note, width, \n",
    "                          break_long_words=False, break_on_hyphens=False, \n",
    "                          replace_whitespace=False, drop_whitespace=False)\n",
    "    \n",
    "    size = 0\n",
    "    for text in texts:\n",
    "        result = client.detect_phi(Text=text)\n",
    "        for entity in result['Entities']:\n",
    "            if entity['Type'] == 'NAME':\n",
    "                outputs[ID][(size+entity['BeginOffset'], size+entity['EndOffset'])] = (entity['Text'], entity['Score'])\n",
    "        size += len(text)\n",
    "    \n",
    "    if count % 100 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2726ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/Polysemy/Output/polysemies-Amazon.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':list(name)} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
