{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be93a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import jsonlines\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc9e8e",
   "metadata": {},
   "source": [
    "### General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad39473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/General/Input/notes-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d241630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b68c84c0ae04938a471f9e70a1cdc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 11:51:05 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-12-29 11:51:06 INFO: Use device: gpu\n",
      "2022-12-29 11:51:06 INFO: Loading: tokenize\n",
      "2022-12-29 11:51:10 INFO: Loading: ner\n",
      "2022-12-29 11:51:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17638922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 1000\n",
      "Finish Processing Note 2000\n",
      "Finish Processing Note 3000\n",
      "Finish Processing Note 4000\n",
      "Finish Processing Note 5000\n",
      "Finish Processing Note 6000\n",
      "Finish Processing Note 7000\n",
      "Finish Processing Note 8000\n",
      "Finish Processing Note 9000\n",
      "Finish Processing Note 10000\n",
      "Finish Processing Note 11000\n",
      "Finish Processing Note 12000\n",
      "Finish Processing Note 13000\n",
      "Finish Processing Note 14000\n",
      "Finish Processing Note 15000\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    doc = nlp(note)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.type == 'PERSON':\n",
    "            outputs[ID][(ent.start_char, ent.end_char)] = ent.text\n",
    "    \n",
    "    if count % 1000 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea32866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/General/Output/notes-Stanza.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':[name]} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb282c4",
   "metadata": {},
   "source": [
    "### Polysemy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b570e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ae6c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b68c84c0ae04938a471f9e70a1cdc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 11:51:05 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-12-29 11:51:06 INFO: Use device: gpu\n",
      "2022-12-29 11:51:06 INFO: Loading: tokenize\n",
      "2022-12-29 11:51:10 INFO: Loading: ner\n",
      "2022-12-29 11:51:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b0b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 100\n",
      "Finish Processing Note 200\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    doc = nlp(note)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.type == 'PERSON':\n",
    "            outputs[ID][(ent.start_char, ent.end_char)] = ent.text\n",
    "    \n",
    "    if count % 100 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3218502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/Polysemy/Output/polysemies-Stanza.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':[name]} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
