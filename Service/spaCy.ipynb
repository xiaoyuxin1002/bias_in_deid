{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48cb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import jsonlines\n",
    "from spacy.tokens import DocBin\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b770c",
   "metadata": {},
   "source": [
    "### General Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c309fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/General/Input/notes-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6de4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c4a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 1000\n",
      "Finish Processing Note 2000\n",
      "Finish Processing Note 3000\n",
      "Finish Processing Note 4000\n",
      "Finish Processing Note 5000\n",
      "Finish Processing Note 6000\n",
      "Finish Processing Note 7000\n",
      "Finish Processing Note 8000\n",
      "Finish Processing Note 9000\n",
      "Finish Processing Note 10000\n",
      "Finish Processing Note 11000\n",
      "Finish Processing Note 12000\n",
      "Finish Processing Note 13000\n",
      "Finish Processing Note 14000\n",
      "Finish Processing Note 15000\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    doc = nlp(note)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            outputs[ID][(ent.start_char, ent.end_char)] = ent.text\n",
    "            \n",
    "    if count % 1000 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c387b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/General/Output/notes-spaCy.jsonl', 'w') as writer:=\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':[name]} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3c581",
   "metadata": {},
   "source": [
    "### Polysemy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877b3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-input.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3bbdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b92e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Processing Note 0\n",
      "Finish Processing Note 100\n",
      "Finish Processing Note 200\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "outputs = defaultdict(dict)\n",
    "for count, (ID, note) in enumerate(notes.items()):\n",
    "    doc = nlp(note)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            outputs[ID][(ent.start_char, ent.end_char)] = ent.text\n",
    "            \n",
    "    if count % 100 == 0: print(f'Finish Processing Note {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19d1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs\n",
    "\n",
    "with jsonlines.open('../Data/Polysemy/Output/polysemies-spaCy.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':list(ID), 'position':list(position), 'name':[name]} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ff2a3",
   "metadata": {},
   "source": [
    "### Finetuning Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cbce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the inputs\n",
    "\n",
    "for type_context in ['general', 'clinical']:\n",
    "    for type_name in ['popular', 'diverse']:\n",
    "        \n",
    "        notes = {}\n",
    "        with jsonlines.open(f'../Data/Finetune/Input/inputs-{type_context}+{type_name}.jsonl', 'r') as reader:\n",
    "            for line in reader:\n",
    "                notes[tuple(line['ID'])] = line['note']\n",
    "                \n",
    "        labels = defaultdict(dict)\n",
    "        with jsonlines.open(f'../Data/Finetune/Input/labels-{type_context}+{type_name}.jsonl', 'r') as reader:\n",
    "            for line in reader:\n",
    "                ID, position, name = map(lambda x:tuple(x), line.values())\n",
    "                labels[ID][position] = name\n",
    "                \n",
    "        nlp = spacy.blank('en')\n",
    "        dbs = {split: DocBin() for split in ['train', 'dev']}\n",
    "        for ID, note in notes.items():\n",
    "            doc = nlp.make_doc(note)\n",
    "            ents = []\n",
    "            for position, name in labels[ID].items():\n",
    "                span = doc.char_span(position[0], position[1], label='PERSON')\n",
    "                if span is not None: ents.append(span)\n",
    "            doc.ents = ents\n",
    "            dbs[ID[0]].add(doc)\n",
    "            \n",
    "        for split, db in dbs.items():\n",
    "            db.to_disk(f'External/spaCy/Data/Finetune/{split}-{type_context}+{type_name}.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy train External/spaCy/Model/config.cfg \\\n",
    "#  --output External/spaCy/Model/0/general+popular/ \\\n",
    "#  --paths.train External/spaCy/Data/Finetune/Input/train-general+popular.spacy \\\n",
    "#  --paths.dev External/spaCy/Data/Finetune/Input/dev-general+popular.spacy \\\n",
    "#  --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb69b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test inputs\n",
    "\n",
    "notes = {}\n",
    "with jsonlines.open('../Data/Finetune/Input/inputs-test.jsonl', 'r') as reader:\n",
    "    for line in reader:\n",
    "        notes[tuple(line['ID'])] = line['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336c5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model, make predictions, save the outputs\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "def test(type_context, type_name, seed):    \n",
    "    nlp = spacy.load(f'External/spaCy/Model/{seed}/{type_context}+{type_name}/model-best')\n",
    "    outputs = defaultdict(dict)\n",
    "    \n",
    "    for count, (ID, note) in enumerate(notes.items()):\n",
    "        doc = nlp(note)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON':\n",
    "                outputs[ID][(ent.start_char, ent.end_char)] = ent.text\n",
    "\n",
    "    with jsonlines.open(f'../Data/Finetune/Output/finetunes-{type_context}+{type_name}-spaCy-{seed}.jsonl', 'w') as writer:\n",
    "        writer.write_all([{'ID':list(ID), 'position':list(position), 'name':[name]} for ID, preds in outputs.items() for position, name in preds.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6257ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Evaluating Seed = 0, Context = general, Name = popular\n",
      "Finish Evaluating Seed = 0, Context = general, Name = diverse\n",
      "Finish Evaluating Seed = 0, Context = clinical, Name = popular\n",
      "Finish Evaluating Seed = 0, Context = clinical, Name = diverse\n",
      "Finish Evaluating Seed = 1, Context = general, Name = popular\n",
      "Finish Evaluating Seed = 1, Context = general, Name = diverse\n",
      "Finish Evaluating Seed = 1, Context = clinical, Name = popular\n",
      "Finish Evaluating Seed = 1, Context = clinical, Name = diverse\n",
      "Finish Evaluating Seed = 2, Context = general, Name = popular\n",
      "Finish Evaluating Seed = 2, Context = general, Name = diverse\n",
      "Finish Evaluating Seed = 2, Context = clinical, Name = popular\n",
      "Finish Evaluating Seed = 2, Context = clinical, Name = diverse\n",
      "Finish Evaluating Seed = 3, Context = general, Name = popular\n",
      "Finish Evaluating Seed = 3, Context = general, Name = diverse\n",
      "Finish Evaluating Seed = 3, Context = clinical, Name = popular\n",
      "Finish Evaluating Seed = 3, Context = clinical, Name = diverse\n",
      "Finish Evaluating Seed = 4, Context = general, Name = popular\n",
      "Finish Evaluating Seed = 4, Context = general, Name = diverse\n",
      "Finish Evaluating Seed = 4, Context = clinical, Name = popular\n",
      "Finish Evaluating Seed = 4, Context = clinical, Name = diverse\n"
     ]
    }
   ],
   "source": [
    "for seed in [0, 1, 2, 3, 4]:\n",
    "    for type_context in ['general', 'clinical']:\n",
    "        for type_name in ['popular', 'diverse']:\n",
    "            test(type_context, type_name, seed)\n",
    "            print(f'Finish Evaluating Seed = {seed}, Context = {type_context}, Name = {type_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
