{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7634da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764c8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# white/black/asian male names with medium popularity in the 2000s\n",
    "\n",
    "race2polysemies = {'white': ['Sydney', 'Faith', 'Forest', 'Cliff', 'June'],\n",
    "                   'black': ['Quincy', 'Cleveland', 'Kenya', 'Prince', 'Ivory'],\n",
    "                   'asian': ['Thai', 'King', 'Long', 'Young', 'Can']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738c9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.copy_size = 1\n",
    "        self.name_tag = ('**NAME-', 11)\n",
    "        self.other_tags = {'**AGE**':'38', '**CONTACT**':'0123456789', '**DATE**':'2100/01/01', \n",
    "                           '**HOSPITAL**':'General Hospital', '**ID**':'100', '**LANGUAGE**':'English', \n",
    "                           '**LOCATION**':'Building 1', '**OTHER**':'_', '**PROFESSION**':'worker'}\n",
    "        \n",
    "        # white/black/asian male names with medium popularity in the 2000s\n",
    "        self.first2last = {3:2, 7:4, 9:5}\n",
    "        self.first_sets = {3: race2polysemies['white'], 7: race2polysemies['black'], 9: race2polysemies['asian']}\n",
    "        self.last_sets = defaultdict(list)           \n",
    "        with open('../Data/General/Input/names-last.csv') as file:\n",
    "            reader = csv.reader(file)\n",
    "            _ = next(reader)\n",
    "            for row in reader:\n",
    "                setID, name = int(row[0]), row[-3]\n",
    "                self.last_sets[setID].append(name)\n",
    "                    \n",
    "    def replace_irrelevant(self, template):\n",
    "        \n",
    "        for tag, fake in self.other_tags.items():\n",
    "            template = template.replace(tag, fake)\n",
    "        return template\n",
    "                    \n",
    "    def find_occurrences(self, note, tag):\n",
    "        \n",
    "        pattern, length = tag\n",
    "        occurrences = []\n",
    "        index = note.find(pattern)\n",
    "        while index != -1:\n",
    "            occurrences.append((index, index+length, note[index:index+length]))\n",
    "            index = note.find(pattern, index+length)\n",
    "        return occurrences\n",
    "                    \n",
    "    def sample_name(self, setID):\n",
    "        \n",
    "        names = {'F':self.first_sets[setID]*4, 'L': self.last_sets[self.first2last[setID]]}         \n",
    "        for each in names.values():\n",
    "            random.shuffle(each)\n",
    "        return names\n",
    "                        \n",
    "    # replace the irrelevant tags, identify the name tags, sample the names, replace the name tags, return the notes and names\n",
    "    def __call__(self, templates):\n",
    "        \n",
    "        input_notes, input_labels = {}, defaultdict(dict)\n",
    "        for templateID, row in templates.iterrows():\n",
    "            template = self.replace_irrelevant(row['text'])\n",
    "            tags = {tag for _, _, tag in self.find_occurrences(template, self.name_tag)}\n",
    "            for setID in self.first2last:\n",
    "                for copyID in range(self.copy_size):\n",
    "                    names = self.sample_name(setID)\n",
    "                    \n",
    "                    name2tag, name2setID = {}, {}\n",
    "                    input_notes[(templateID, setID, copyID)] = template\n",
    "                    for tag in tags:\n",
    "                        personID = int(tag[7])\n",
    "                        name = ' '.join([names['F'][personID], names['L'][personID]])\n",
    "                        \n",
    "                        name2tag[name] = tag\n",
    "                        name2setID[name] = setID\n",
    "                        input_notes[(templateID, setID, copyID)] = input_notes[(templateID, setID, copyID)].replace(tag, name)\n",
    "                        \n",
    "                    for name in name2tag:\n",
    "                        for start, end, _ in self.find_occurrences(input_notes[(templateID, setID, copyID)], (name, len(name))):\n",
    "                            input_labels[(templateID, setID, copyID)][(start, end)] = (name, name2tag[name], name2setID[name])\n",
    "                            \n",
    "                    name_overlap = set()\n",
    "                    positions = list(input_labels[(templateID, setID, copyID)].keys())\n",
    "                    for i in range(len(positions)):\n",
    "                        for j in range(i+1, len(positions)):\n",
    "                            if positions[i][0]<=positions[j][0] and positions[i][1]>=positions[j][1]: name_overlap.add(positions[j])\n",
    "                    for start, end in name_overlap:\n",
    "                        del input_labels[(templateID, setID, copyID)][(start, end)]\n",
    "                        \n",
    "        return input_notes, input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecde38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the inputs\n",
    "\n",
    "namer = Namer()\n",
    "templates = pd.read_csv('../Data/General/Input/notes-base.csv')\n",
    "polysemies_input, polysemies_label = namer(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47d59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inputs\n",
    "\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-input.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':ID, 'note':note} for ID, note in polysemies_input.items()])\n",
    "with jsonlines.open('../Data/Polysemy/Input/polysemies-label.jsonl', 'w') as writer:\n",
    "    writer.write_all([{'ID':ID, 'position':position, 'name':name} for ID, labels in polysemies_label.items() for position, name in labels.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
